{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from config import test_dataset_imagename_front,val_dataset_imagename_front\n",
    "\n",
    "\n",
    "# ------------------ #\n",
    "from tensorflow.keras import models, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Balanceacc\n",
    "\n",
    "from models import efficientNetV2B0_model, efficientNetV2B3_model\n",
    "from config import efficientNet_config\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from utils import plt_heatmap, plt_roccurve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "import os\n",
    "# 使用第一張 GPU 卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判斷膽管方向是 上面 或 下面 \n",
    "# 用整張影像 分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths     = sorted(glob('../../classification/dataset_186video_20230323/train/1/*.png'))                  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 換資料集\n",
    "val_img_paths       = sorted(glob('../../classification/dataset_186video_20230323/validation/1/*.png'))\n",
    "\n",
    "train_img_arrays = []\n",
    "train_img_labels = []\n",
    "validation_img_arrays = []\n",
    "validation_img_labels = []\n",
    "\n",
    "for train_img_path in train_img_paths:\n",
    "    img_array = cv.imread(train_img_path)\n",
    "    img_array = cv.resize(img_array,(224, 224))     # efficientNetv2B0\n",
    "    # image array\n",
    "    train_img_arrays.append(img_array)\n",
    "    # label\n",
    "    train_img_labels.append([0])\n",
    "\n",
    "    smoothed_img2_ROTATE_180 = cv.rotate(img_array, cv.ROTATE_180)   # 轉180度\n",
    "    # image array(rotate 180) \n",
    "    train_img_arrays.append(smoothed_img2_ROTATE_180)\n",
    "    # label(rotate 180)\n",
    "    train_img_labels.append([1])\n",
    "\n",
    "# 驗證集\n",
    "for val_img_path in val_img_paths:\n",
    "    img_array = cv.imread(val_img_path)\n",
    "    img_array = cv.resize(img_array,(224, 224))     # efficientNetv2B0\n",
    "\n",
    "    # image array\n",
    "    validation_img_arrays.append(img_array)\n",
    "    # label\n",
    "    validation_img_labels.append([0])\n",
    "\n",
    "    smoothed_img2_ROTATE_180 = cv.rotate(img_array, cv.ROTATE_180)\n",
    "    # image array(rotate 180) \n",
    "    validation_img_arrays.append(smoothed_img2_ROTATE_180)\n",
    "    # label(rotate 180)\n",
    "    validation_img_labels.append([1])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集維度=  (6662, 224, 224, 3)\n",
      "測試集維度=  (2692, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_img_arrays = np.array(train_img_arrays)\n",
    "train_img_labels = np.array(train_img_labels)\n",
    "validation_img_arrays = np.array(validation_img_arrays)\n",
    "validation_img_labels = np.array(validation_img_labels)\n",
    "\n",
    "train_img_arrays, train_img_labels           = shuffle(train_img_arrays,train_img_labels)\n",
    "validation_img_arrays, validation_img_labels = shuffle(validation_img_arrays,validation_img_labels)\n",
    "print('訓練集維度= ',train_img_arrays.shape)\n",
    "print('測試集維度= ',validation_img_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b0 (Function  (None, 1280)             5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,920,593\n",
      "Trainable params: 5,859,985\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = efficientNetV2B0_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', \n",
    "                        Balanceacc()\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '20230410'\n",
    "checkpoint_filepath = '../model/202303/{}.weights'.format(day)\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_balanceacc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "# learning rate 降低\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "#                               factor=0.1,\n",
    "#                               patience=5, \n",
    "#                               min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint_callback, \n",
    "             #reduce_lr\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 19:47:50.191513: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/209 [=======================>......] - ETA: 4s - loss: 0.1666 - accuracy: 0.9475 - balanceacc_1: 0.9475"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "epochs = 200\n",
    "history = model.fit(\n",
    "      x = train_img_arrays,\n",
    "      y = train_img_labels,\n",
    "      validation_data = (validation_img_arrays,validation_img_labels),      \n",
    "      epochs          = epochs,\n",
    "      verbose         = 1,\n",
    "      callbacks       = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss         = history.history['loss']\n",
    "val_loss     = history.history['val_loss']\n",
    "accuracy     = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "BlA          = history.history['balanceacc']\n",
    "val_BlA      = history.history['val_balanceacc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "min_valloss_x = val_loss.index(min(val_loss)) + 1\n",
    "min_valloss_y = min(val_loss)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, loss, 'r')     \n",
    "plt.plot(x, val_loss, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(min_valloss_x, min_valloss_y, 'd', color='g')\n",
    "plt.text(min_valloss_x, min_valloss_y, \"({},{})\".format(min_valloss_x,round(min_valloss_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.ylim((0, 1.0))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss')\n",
    "plt.savefig('../model/202303/{}_loss.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valacc_x = val_accuracy.index(max(val_accuracy)) + 1\n",
    "max_valacc_y = max(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, accuracy, 'r')     \n",
    "plt.plot(x, val_accuracy, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valacc_x, max_valacc_y, 'd', color='g')\n",
    "plt.text(max_valacc_x, max_valacc_y, \"({},{})\".format(max_valacc_x, round(max_valacc_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy')\n",
    "plt.savefig('../model/202303/{}_acc.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valBlA_x = val_BlA.index(max(val_BlA)) + 1\n",
    "max_valBlA_y = max(val_BlA)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, BlA, 'r')     \n",
    "plt.plot(x, val_BlA, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valBlA_x, max_valBlA_y, 'd', color='g')\n",
    "plt.text(max_valBlA_x, max_valBlA_y, \"({},{})\".format(max_valBlA_x, round(max_valBlA_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['balance accuracy','val_balance accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('balance accuracy')\n",
    "plt.title('balance accuracy')\n",
    "plt.savefig('../model/202303/{}_BlA.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = history.history\n",
    "# Save it under the form of a json file\n",
    "json.dump(history_dict, open('../model/202303/{}.history'.format(day), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
