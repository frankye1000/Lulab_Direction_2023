{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from config import test_dataset_imagename_front,val_dataset_imagename_front\n",
    "\n",
    "\n",
    "# ------------------ #\n",
    "from tensorflow.keras import models, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Balanceacc\n",
    "\n",
    "from models import efficientNetV2B0_model, efficientNetV2B3_model\n",
    "from config import efficientNet_config\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from utils import plt_heatmap, plt_roccurve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "import os\n",
    "# 使用第一張 GPU 卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判斷膽管方向是 上面 或 下面 \n",
    "# 用bbox切割完後的影像 分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 186資料集\n",
    "# 要分成train 和 validation\n",
    "\n",
    "training_img_paths     = sorted(glob('../dataset_20230323/training_dataset/cropped_img/*.png'))  \n",
    "train_img_paths = []           \n",
    "val_img_paths = []\n",
    "for img_path in training_img_paths:\n",
    "    imgname_front = img_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "    if imgname_front in val_dataset_imagename_front:\n",
    "        val_img_paths.append(img_path)\n",
    "    else:\n",
    "        train_img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = []\n",
    "train_img_labels = []\n",
    "validation_img_arrays = []\n",
    "validation_img_labels = []\n",
    "\n",
    "for train_img_path in train_img_paths:\n",
    "    img_array = cv.imread(train_img_path)\n",
    "    img_array = cv.resize(img_array,(224, 224))     # efficientNetv2B0\n",
    "\n",
    "    # image array\n",
    "    train_img_arrays.append(img_array)\n",
    "    # label\n",
    "    train_img_labels.append([0])\n",
    "\n",
    "    smoothed_img2_ROTATE_180 = cv.rotate(img_array, cv.ROTATE_180)   # 轉180度\n",
    "    # image array(rotate 180) \n",
    "    train_img_arrays.append(smoothed_img2_ROTATE_180)\n",
    "    # label(rotate 180)\n",
    "    train_img_labels.append([1])\n",
    "\n",
    "# 驗證集\n",
    "for val_img_path in val_img_paths:\n",
    "    img_array = cv.imread(val_img_path)\n",
    "    img_array = cv.resize(img_array,(224, 224))     # efficientNetv2B0\n",
    "\n",
    "\n",
    "    # image array\n",
    "    validation_img_arrays.append(img_array)\n",
    "    # label\n",
    "    validation_img_labels.append([0])\n",
    "\n",
    "    smoothed_img2_ROTATE_180 = cv.rotate(img_array, cv.ROTATE_180)\n",
    "    # image array(rotate 180) \n",
    "    validation_img_arrays.append(smoothed_img2_ROTATE_180)\n",
    "    # label(rotate 180)\n",
    "    validation_img_labels.append([1])   \n",
    "    \n",
    "\n",
    "    # ## plot img\n",
    "    # plt.figure()\n",
    "    # f, axarr = plt.subplots(1, 2,figsize=(6,3)) \n",
    "    # axarr[0].imshow(cv.cvtColor(smoothed_img2, cv.COLOR_BGR2RGB))\n",
    "    # axarr[1].imshow(cv.cvtColor(smoothed_img2_ROTATE_180, cv.COLOR_BGR2RGB))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = np.array(train_img_arrays)\n",
    "train_img_labels = np.array(train_img_labels)\n",
    "validation_img_arrays = np.array(validation_img_arrays)\n",
    "validation_img_labels = np.array(validation_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays, train_img_labels           = shuffle(train_img_arrays,train_img_labels)\n",
    "validation_img_arrays, validation_img_labels = shuffle(validation_img_arrays,validation_img_labels)\n",
    "print('訓練集維度= ',train_img_arrays.shape)\n",
    "print('測試集維度= ',validation_img_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientNetV2B0_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', \n",
    "                        Balanceacc()\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '20230409'\n",
    "checkpoint_filepath = '../model/202303/{}.weights'.format(day)\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_balanceacc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "# learning rate 降低\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "#                               factor=0.1,\n",
    "#                               patience=5, \n",
    "#                               min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint_callback, \n",
    "             #reduce_lr\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "epochs = 200\n",
    "history = model.fit(\n",
    "      x = train_img_arrays,\n",
    "      y = train_img_labels,\n",
    "      validation_data = (validation_img_arrays,validation_img_labels),      \n",
    "      epochs          = epochs,\n",
    "      verbose         = 1,\n",
    "      callbacks       = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss         = history.history['loss']\n",
    "val_loss     = history.history['val_loss']\n",
    "accuracy     = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "BlA          = history.history['balanceacc']\n",
    "val_BlA      = history.history['val_balanceacc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "min_valloss_x = val_loss.index(min(val_loss)) + 1\n",
    "min_valloss_y = min(val_loss)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, loss, 'r')     \n",
    "plt.plot(x, val_loss, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(min_valloss_x, min_valloss_y, 'd', color='g')\n",
    "plt.text(min_valloss_x, min_valloss_y, \"({},{})\".format(min_valloss_x,round(min_valloss_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.ylim((0, 1.0))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss')\n",
    "plt.savefig('../model/202303/{}_loss.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valacc_x = val_accuracy.index(max(val_accuracy)) + 1\n",
    "max_valacc_y = max(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, accuracy, 'r')     \n",
    "plt.plot(x, val_accuracy, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valacc_x, max_valacc_y, 'd', color='g')\n",
    "plt.text(max_valacc_x, max_valacc_y, \"({},{})\".format(max_valacc_x, round(max_valacc_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy')\n",
    "plt.savefig('../model/202303/{}_acc.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valBlA_x = val_BlA.index(max(val_BlA)) + 1\n",
    "max_valBlA_y = max(val_BlA)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, BlA, 'r')     \n",
    "plt.plot(x, val_BlA, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valBlA_x, max_valBlA_y, 'd', color='g')\n",
    "plt.text(max_valBlA_x, max_valBlA_y, \"({},{})\".format(max_valBlA_x, round(max_valBlA_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['balance accuracy','val_balance accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('balance accuracy')\n",
    "plt.title('balance accuracy')\n",
    "plt.savefig('../model/202303/{}_BlA.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = history.history\n",
    "# Save it under the form of a json file\n",
    "json.dump(history_dict, open('../model/202303/{}.history'.format(day), 'w'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類模型(最後一個epoch模型) 測試集結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_paths     = sorted(glob('../dataset_20230323/test_dataset/cropped_img/*.png'))                  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! 換資料集\n",
    "\n",
    "test_img_arrays = []\n",
    "test_img_labels = []\n",
    "\n",
    "for test_img_path in test_img_paths:\n",
    "    img_array = cv.imread(test_img_path)\n",
    "    img_array = cv.resize(img_array,(224, 224))     # efficientNetv2B0\n",
    "\n",
    "    # 兩次雙邊濾波\n",
    "    # smoothed_img  = cv.bilateralFilter(img_array, 15, 50,  50)\n",
    "    # smoothed_img2 = cv.bilateralFilter(smoothed_img, 15, 50, 50)\n",
    "    # image array\n",
    "    test_img_arrays.append(img_array)\n",
    "    # label\n",
    "    test_img_labels.append([0])\n",
    "\n",
    "    smoothed_img2_ROTATE_180 = cv.rotate(img_array, cv.ROTATE_180)\n",
    "    # image array(rotate 180) \n",
    "    test_img_arrays.append(smoothed_img2_ROTATE_180)\n",
    "    # label(rotate 180)\n",
    "    test_img_labels.append([1])\n",
    "\n",
    "\n",
    "# to numpy array\n",
    "test_img_arrays = np.array(test_img_arrays)\n",
    "test_img_labels = np.array(test_img_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 也將最後一個epoch訓練的模型存下來\n",
    "model.save(\"../model/202303/{}_lastepoch.h5\".format(day))\n",
    "\n",
    "pred_result = model.predict(test_img_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_img_labels, pred_result, pos_label=1) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt_roccurve(fpr,tpr,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = np.where(pred_result > 0.5, 1,0)\n",
    "tn, fp, fn, tp = confusion_matrix(test_img_labels, pred_result).ravel()\n",
    "sensitivity = round(tp / (tp+fn), 4)\n",
    "specificity = round(tn / (tn+fp), 4)\n",
    "balanced_acc= round((sensitivity+specificity)/2, 4)\n",
    "precision   = round(tp / (tp+fp), 4)\n",
    "f1score     = round(2/((1/precision)+(1/sensitivity)), 4)\n",
    "accuracy    = round((tp+tn)/(tn+fp+fn+tp), 4)\n",
    "\n",
    "print('Sensitivity= ',sensitivity)\n",
    "print('Specificity= ',specificity)\n",
    "print('Balanced_acc= ',balanced_acc)\n",
    "print('Precision= ', precision)\n",
    "print('f1score= ', f1score)\n",
    "print('Accuracy= ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_heatmap([[tp,fn],[fp,tn]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
